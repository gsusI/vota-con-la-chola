#!/usr/bin/env python3
"""Append-only heartbeat lane for initdoc actionable-tail digest."""

from __future__ import annotations

import argparse
import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

DEFAULT_HEARTBEAT_JSONL = Path("docs/etl/runs/initdoc_actionable_tail_digest_heartbeat.jsonl")


def now_utc_iso() -> str:
    return datetime.now(timezone.utc).replace(microsecond=0).isoformat()


def _safe_text(value: Any) -> str:
    if value is None:
        return ""
    return str(value).strip()


def _to_int(value: Any, default: int = 0) -> int:
    try:
        return int(value)
    except Exception:  # noqa: BLE001
        return int(default)


def _to_float(value: Any, default: float = 0.0) -> float:
    try:
        return float(value)
    except Exception:  # noqa: BLE001
        return float(default)


def _safe_obj(value: Any) -> dict[str, Any]:
    return value if isinstance(value, dict) else {}


def _safe_list_str(value: Any) -> list[str]:
    if not isinstance(value, list):
        return []
    return [_safe_text(v) for v in value if _safe_text(v)]


def _normalize_status(value: Any) -> str:
    token = _safe_text(value).lower()
    if token in {"ok", "degraded", "failed"}:
        return token
    return "failed"


def parse_args(argv: list[str] | None = None) -> argparse.Namespace:
    p = argparse.ArgumentParser(description="Append heartbeat JSONL for initdoc actionable-tail digest")
    p.add_argument(
        "--digest-json",
        required=True,
        help="Input digest JSON generated by report_initdoc_actionable_tail_digest.py",
    )
    p.add_argument(
        "--heartbeat-jsonl",
        default=str(DEFAULT_HEARTBEAT_JSONL),
        help=f"Heartbeat JSONL path (default: {DEFAULT_HEARTBEAT_JSONL})",
    )
    p.add_argument(
        "--strict",
        action="store_true",
        help="Exit with code 4 when heartbeat is invalid or status=failed.",
    )
    p.add_argument("--out", default="", help="Optional JSON output path")
    return p.parse_args(argv)


def build_heartbeat(
    digest_payload: dict[str, Any],
    *,
    digest_path: str,
) -> dict[str, Any]:
    digest = _safe_obj(digest_payload)
    if "status" not in digest and isinstance(digest.get("digest"), dict):
        digest = _safe_obj(digest.get("digest"))

    totals = _safe_obj(digest.get("totals"))
    checks = _safe_obj(digest.get("checks"))
    thresholds = _safe_obj(digest.get("thresholds"))

    source_ids = _safe_list_str(digest.get("initiative_source_ids"))
    status = _normalize_status(digest.get("status"))
    run_at = _safe_text(digest.get("generated_at")) or now_utc_iso()
    contract_generated_at = _safe_text(digest.get("contract_generated_at"))

    total_missing = _to_int(totals.get("total_missing"), 0)
    redundant_missing = _to_int(totals.get("redundant_missing"), 0)
    actionable_missing = _to_int(totals.get("actionable_missing"), 0)
    fallback_pct = (float(actionable_missing) / float(total_missing)) if total_missing > 0 else 0.0
    actionable_missing_pct = _to_float(totals.get("actionable_missing_pct"), fallback_pct)

    strict_fail_reasons = _safe_list_str(digest.get("strict_fail_reasons"))
    actionable_queue_empty = bool(checks.get("actionable_queue_empty")) if "actionable_queue_empty" in checks else (
        actionable_missing == 0
    )

    hb_id_parts = [
        contract_generated_at,
        run_at,
        status,
        ",".join(source_ids),
        str(actionable_missing),
        f"{actionable_missing_pct:.6f}",
    ]
    heartbeat_id = "|".join(hb_id_parts)

    return {
        "run_at": run_at,
        "heartbeat_id": heartbeat_id,
        "digest_path": _safe_text(digest_path),
        "digest_generated_at": _safe_text(digest.get("generated_at")),
        "contract_generated_at": contract_generated_at,
        "initiative_source_ids": source_ids,
        "status": status,
        "total_missing": total_missing,
        "redundant_missing": redundant_missing,
        "actionable_missing": actionable_missing,
        "actionable_missing_pct": round(float(actionable_missing_pct), 6),
        "actionable_queue_empty": bool(actionable_queue_empty),
        "max_actionable_missing": _to_int(thresholds.get("max_actionable_missing"), 0),
        "max_actionable_missing_pct": _to_float(thresholds.get("max_actionable_missing_pct"), 0.0),
        "strict_fail_count": len(strict_fail_reasons),
        "strict_fail_reasons": strict_fail_reasons,
    }


def validate_heartbeat(heartbeat: dict[str, Any]) -> list[str]:
    reasons: list[str] = []

    if not _safe_text(heartbeat.get("run_at")):
        reasons.append("missing_run_at")
    if not _safe_text(heartbeat.get("heartbeat_id")):
        reasons.append("missing_heartbeat_id")

    status = _normalize_status(heartbeat.get("status"))
    if status not in {"ok", "degraded", "failed"}:
        reasons.append("invalid_status")

    total_missing = _to_int(heartbeat.get("total_missing"), 0)
    redundant_missing = _to_int(heartbeat.get("redundant_missing"), 0)
    actionable_missing = _to_int(heartbeat.get("actionable_missing"), 0)
    actionable_missing_pct = _to_float(heartbeat.get("actionable_missing_pct"), 0.0)

    if total_missing < 0:
        reasons.append("invalid_total_missing")
    if redundant_missing < 0:
        reasons.append("invalid_redundant_missing")
    if actionable_missing < 0:
        reasons.append("invalid_actionable_missing")
    if actionable_missing_pct < 0:
        reasons.append("invalid_actionable_missing_pct")
    if redundant_missing + actionable_missing > total_missing:
        reasons.append("invalid_missing_partition")

    strict_fail_reasons = _safe_list_str(heartbeat.get("strict_fail_reasons"))
    strict_fail_count = _to_int(heartbeat.get("strict_fail_count"), -1)
    if strict_fail_count != len(strict_fail_reasons):
        reasons.append("strict_fail_count_mismatch")

    queue_empty = bool(heartbeat.get("actionable_queue_empty"))
    if queue_empty != (actionable_missing == 0):
        reasons.append("actionable_queue_empty_mismatch")

    return reasons


def read_history_entries(history_path: Path) -> list[dict[str, Any]]:
    if not history_path.exists():
        return []

    rows: list[dict[str, Any]] = []
    raw = history_path.read_text(encoding="utf-8")
    lines = [line for line in raw.splitlines() if _safe_text(line)]
    for idx, line in enumerate(lines, start=1):
        try:
            entry = json.loads(line)
            rows.append({"line_no": idx, "malformed_line": False, "entry": _safe_obj(entry)})
        except Exception:  # noqa: BLE001
            rows.append({"line_no": idx, "malformed_line": True, "entry": {}})
    return rows


def history_has_heartbeat(rows: list[dict[str, Any]], heartbeat_id: str) -> bool:
    needle = _safe_text(heartbeat_id)
    if not needle:
        return False
    for row in rows:
        if bool(row.get("malformed_line")):
            continue
        entry = _safe_obj(row.get("entry"))
        if _safe_text(entry.get("heartbeat_id")) == needle:
            return True
    return False


def append_heartbeat(history_path: Path, heartbeat: dict[str, Any]) -> None:
    history_path.parent.mkdir(parents=True, exist_ok=True)
    with history_path.open("a", encoding="utf-8") as fh:
        fh.write(json.dumps(heartbeat, ensure_ascii=False) + "\n")


def main(argv: list[str] | None = None) -> int:
    args = parse_args(argv)

    digest_path = Path(str(args.digest_json))
    if not digest_path.exists():
        print(json.dumps({"error": f"digest json not found: {digest_path}"}, ensure_ascii=False))
        return 2

    try:
        digest_payload = json.loads(digest_path.read_text(encoding="utf-8"))
    except Exception as exc:  # noqa: BLE001
        print(json.dumps({"error": f"invalid digest json: {exc}"}, ensure_ascii=False))
        return 3

    if not isinstance(digest_payload, dict):
        print(json.dumps({"error": "invalid digest json: root must be object"}, ensure_ascii=False))
        return 3

    heartbeat_path = Path(str(args.heartbeat_jsonl))
    report: dict[str, Any] = {
        "generated_at": now_utc_iso(),
        "strict": bool(args.strict),
        "input_path": str(digest_path),
        "heartbeat_path": str(heartbeat_path),
        "history_size_before": 0,
        "history_size_after": 0,
        "history_malformed_lines_before": 0,
        "appended": False,
        "duplicate_detected": False,
        "validation_errors": [],
        "heartbeat": {},
    }

    try:
        heartbeat = build_heartbeat(digest_payload, digest_path=str(digest_path))
        report["heartbeat"] = heartbeat
        report["validation_errors"] = validate_heartbeat(heartbeat)

        history_before = read_history_entries(heartbeat_path)
        report["history_size_before"] = len(history_before)
        report["history_malformed_lines_before"] = sum(1 for row in history_before if bool(row.get("malformed_line")))

        if not report["validation_errors"]:
            report["duplicate_detected"] = history_has_heartbeat(history_before, _safe_text(heartbeat.get("heartbeat_id")))
            if not report["duplicate_detected"]:
                append_heartbeat(heartbeat_path, heartbeat)
                report["appended"] = True

        report["history_size_after"] = int(report["history_size_before"]) + (1 if report["appended"] else 0)
    except Exception as exc:  # noqa: BLE001
        report["validation_errors"] = [f"runtime_error:{type(exc).__name__}:{exc}"]
        report["history_size_after"] = int(report["history_size_before"])

    payload = json.dumps(report, ensure_ascii=False, indent=2)
    print(payload)

    out_path = Path(str(args.out).strip()) if str(args.out).strip() else None
    if out_path is not None:
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(payload + "\n", encoding="utf-8")

    status = _normalize_status(_safe_obj(report.get("heartbeat")).get("status"))
    if bool(args.strict) and (len(list(report.get("validation_errors") or [])) > 0 or status == "failed"):
        return 4
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
